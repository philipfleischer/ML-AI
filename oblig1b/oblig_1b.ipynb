{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41bd954",
   "metadata": {},
   "source": [
    "# IN1160 – Oblig 1b: Klassifisering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b2c5e",
   "metadata": {},
   "source": [
    "**Våren 2026**\n",
    "\n",
    "Det er en god idé å lese gjennom hele oppgavesettet før dere setter i gang.\n",
    "Dersom dere har spørsmål så kan dere:\n",
    "\n",
    "- gå i gruppetime,\n",
    "- spørre på Discourse\n",
    "- eller sende epost til in1160-hjelp@ifi.uio.no dersom alternativene over av en eller annen grunn ikke passer for spørsmålet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41b3ab",
   "metadata": {},
   "source": [
    "## Innlevering\n",
    "\n",
    "Oppgaven leveres innen 25.02. klokken 23.59 i [Devilry](https://devilry.ifi.uio.no/).\n",
    "\n",
    "Innleveringen skal bestå av én Jupyter notebook med både kode og tilhørende forklaringer. **Før innlevering skal du kjøre gjennom hele notebooken, før du lagrer siste gang. Den bør kjøre uten å feile og vise den grafikken og de utskriftene som skal være med.**\n",
    "\n",
    "Vi understreker at innlevering av kode alene ikke er nok for å bestå oppgaven – vi forventer at notebooken også skal inneholde kommentarer (på norsk eller engelsk) på hva dere har gjort og begrunnelser for valgene dere har tatt underveis.\n",
    "La enhver oblig bli en trening i å formidle forskning. Bruk helst hele setninger, og matematiske formler om nødvendig. Resultater skal presenteres i tabeller på en oversiktlig måte.\n",
    "Det å forklare med egne ord, bruke begreper vi har gått gjennom på forelesningene og å forklare og reflektere over løsningene deres er en viktig del av læringsprosessen – ta det på alvor!\n",
    "\n",
    "Når det gjelder bruk av generative prateroboter (ChatGPT og lignende): Dere kan bruke dem som en \"sparringspartner\", for eksempel for å forklare noe dere ikke helt har forstått. Dere har imidlertid ikke lov til å bruke dem til å generere løsninger (enten delvis eller fullstendig) til noen av oppgavene. Funksjoner for automatisk skriving av kode, som Copilot i VS Code, må derfor også være deaktivert mens dere jobber på obligen.  \n",
    "Bruker dere KI-verktøy vil vi også at dere kort beskriver hvordan dere har brukt dem under arbeidet med oppgaven.\n",
    "\n",
    "Det er ikke mulighet for omlevering av obliger som ikke bestås.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223c95e",
   "metadata": {},
   "source": [
    "## Bakgrunn\n",
    "\n",
    "I oblig 1a lagde dere vektorer for ord. Disse baserte seg på hvilke andre ord vi fant i setningen til ordet. Vi så videre at vi kan bruke cosinuslikhet til beregne hvor like to ordvektorer er. \n",
    "I denne obligen skal vi benytte oss av lignende metoder, men løfte blikket fra setningsnivå til dokumentnivå for å gjøre dokumentklassifisering.\n",
    "\n",
    "Vi skal jobbe med datasettet Norwegian Review Corpus (NoReC) som består av anmeldelser hentet fra en rekke norske nettaviser.\n",
    "Dette datasettet består av over 43 000 dokumenter blant annet tagget med hvilket tema dokumentet diskuterer, som f.eks. musikk, film og TV, spill og restauranter.\n",
    "\n",
    "En full rad av NoReC er tagget slik:\n",
    "\n",
    "| id | split | rating | category | day | month | year | excerpt | language | source | authors | title | url | text |\n",
    "|--------|-------|---|-------|---|---|------|----|----|--------|--------------|---------|------------|---------|\n",
    "| 001160 | train | 4 | music | 3 | 7 | 2009 | nb | p3 | Andreas Øverland | Ikke helt rett West | https://p3.no/musikk/kategori/anmeldelser/ikke-helt-rett-west | Ikke helt rett West | Kanye West, Roskilde ... |\n",
    "\n",
    "\n",
    "Mer info finner dere sammen med datasettet [her](https://huggingface.co/datasets/ltg/norec_document).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf952d",
   "metadata": {},
   "source": [
    "## Oppgave 1 – Forberede data\n",
    "\n",
    "I denne oppgaven skal dere laste inn NoReC-datasettet, for å så dele det inn i splitter til trening, validering og testing. \n",
    "For å hente hente NoReC-datasettet bruker dere funksjonen `load_dataset()`, som vist her:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ltg/norec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f3bf8",
   "metadata": {},
   "source": [
    "### Oppgave 1.1 – Oppdeling av datasett (3 poeng)\n",
    "\n",
    "Dere skal nå hente ut ønsket data fra datasettet. Dette skal dere gjøre med funksjonen `prepare_data()`.\n",
    "Denne funksjonen tar inn datasettet og en spesifisert splitt som argumenter og skal returnere to lister: en liste med dokumenttekster og en liste med den respektive kategorien for hvert av dokumentene.\n",
    "Det er viktig at disse følger hverandre – altså at kategorien for teksten på indeks $i$ i dokumentlista finnes på indeks $i$ i kategorilista. Listene skal derfor også ha samme lengde.\n",
    "\n",
    "Datasettet er strukturert som en ordbok. For hver av nøklene 'train', 'validation' og 'test' vil dere finne en ny ordbok som blant annet har nøklene 'category' og 'text'.\n",
    "\n",
    "For å begrense omfanget av dataene vår skal vi begrense oss til kategoriene 'games', 'restaurants' og 'literature'. Tekster og tagger fra alle andre kategorier skal dere altså ikke ta med videre.\n",
    "\n",
    "Skriv ferdig funksjonen `prepare_data()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 1.1\n",
    "def prepare_data(dataset, split):\n",
    "    \"\"\"Henter ønsket data fra datasettet.\n",
    "\n",
    "    Argumenter:\n",
    "    - dataset : NoReC-datasettet.\n",
    "    - split   : En streng som spesifiserer hvilken splitt vi ønsker.\n",
    "\n",
    "    Returnerer:\n",
    "    - data   : En liste over dokument-tekstene fra spesifisert splitt.\n",
    "    - labels : En liste over hvilken kategori dokumentet tilhører.\n",
    "\n",
    "    De returnerte listene skal være like lange og ha samme rekkefølge.\n",
    "    For dokumentet på data[i] skal vi altså kunne finne det tilhørende\n",
    "    kategori i labels[i].\n",
    "    \"\"\"\n",
    "\n",
    "    # Din kode her\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16564b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etter å ha implementert `prepare_data()` skal dere kunne dele opp dataene slik:\n",
    "# Treningsdata\n",
    "train_data, train_labels = prepare_data(dataset, \"train\")\n",
    "\n",
    "# Valideringsdata\n",
    "dev_data, dev_labels = prepare_data(dataset, \"validation\")\n",
    "\n",
    "# Testdata\n",
    "test_data, test_labels = prepare_data(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97776456",
   "metadata": {},
   "source": [
    "### Oppgave 1.2 – Analyse av splitter (2 poeng)\n",
    "\n",
    "Nå som dere har delt opp datasettet i de ulike splittene, skal dere gjøre en enkel analyse av disse.\n",
    "Dere skal her telle opp hvor mange dokumenter det er i hver av de tre splittene og regne ut fordelingen av de ulike kategoriene i hver av splittene.\n",
    "\n",
    "Presenter resultatene i en markdown-tabell som viser antall dokumenter og prosentvis fordeling av de ulike kategoriene i hver av splittene.\n",
    "Skriv en kort kommentar om hva dere observerer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c801bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed9fcf",
   "metadata": {},
   "source": [
    "#### Oppgave 1.2 – Tekstbesvarelse\n",
    "\n",
    "_Legg inn tabellen din her. Hva ser du av resultatene?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8531e61",
   "metadata": {},
   "source": [
    "## Oppgave 2\n",
    "\n",
    "I oblig 1a lagde dere en egen klasse som lagde ordvektorer. I denne oppgaven skal dere benytte dere av scikit-learn sin `CountVectorizer`. Denne fungerer stort sett på samme måte som den klassen dere lagde i oblig 1a, men den gjør blant annet tokenisering på egenhånd. Dere kan altså sende inn dokumentene som sammenhengende strenger i stedet for som lister av tokens. Klassen har også nyttige parametere som kan hjelpe oss med å begrense vokabularet vårt, slik vi gjorde manuelt i 1a.\n",
    "\n",
    "`CountVectorizer` importeres i cellen under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e33c490",
   "metadata": {},
   "source": [
    "### Oppgave 2.1 – Vektorisering (3 poeng)\n",
    "\n",
    "Dere skal her bruke `CountVectorizer` til å lage vektorer av dokumentene. \n",
    "Her må dere først initialisere klassen med parameteren `max_features` satt til 5000, slik at vi bare bruker de mest frekvente ordene. I denne obligen bryr vi oss ikke med å fjerne stoppord, selv om det er mulig gjennom parameteren `stop_words`.\n",
    "\n",
    "Dere må så bruke metoden `.fit()` for å identifisere vokabularet modellen skal bruke. Her sender dere inn treningssettet som parameter. \n",
    "\n",
    "Etter dette kan dere bruke vektorisereren med `.transform()`, der dere sender inn hver datasplitt. Dere skal da få returnert en liste med vektoriserte versjoner av dokumentene. Lista har samme rekkefølge som dokumentene dere sendte inn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac027282",
   "metadata": {},
   "source": [
    "### Oppgave 2.2 – Visualisering (2 poeng)\n",
    "\n",
    "Vi har nå vektorrepresentasjoner av dataene. Disse vektorene kan plasseres i et _vektorrom_, som så vi kan visualisere.\n",
    "Å visualisere dataene kan hjelpe oss med å forstå sammenhenger mellom dataene.\n",
    "Vi har laget en ferdig funksjon `scatter_plot()` som dere kan bruke.\n",
    "Denne tar to argumenter:\n",
    " - `vectors` – De vektoriserte dokumentene\n",
    " - `labels`  – Den tilhørende lista med kategorier\n",
    "\n",
    "Bruk funksjonen `scatter_plot()` til å visualisere dokumentvektorene for treningssettet. Beskriv og diskuter hva du ser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b783299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def scatter_plot(vectors, labels):\n",
    "    \"\"\"\n",
    "    Gir en 2D-visualisering av vektorrommet.\n",
    "\n",
    "    Argumenter:\n",
    "    - vectors : Vektoriserte data.\n",
    "    - labels  : De tilhørende taggene.\n",
    "\n",
    "    Legg merke til at vi her går fra 5000 dimensjoner (antall trekk)\n",
    "    til kun 2 (x-aksen og y-aksen). Dette gjøres ved å bruke\n",
    "    Singular Value Decomposition (SVD). Dette er ikke pensum, men\n",
    "    kort fortalt er det en teknikk for dimensjonsreduksjon som\n",
    "    bevarer mest mulig informasjon fra de opprinnelige vektorene.\n",
    "    \"\"\"\n",
    "    svd = TruncatedSVD(2).fit_transform(vectors)\n",
    "    x_axis, y_axis = svd[:, 0], svd[:, 1]\n",
    "\n",
    "    unique_labels = list(set(labels))\n",
    "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "    numeric_labels = [label_to_int[l] for l in labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    color_map = plt.cm.get_cmap(\"jet\", len(set(labels)))\n",
    "    scatter = plt.scatter(x_axis, y_axis, c=numeric_labels, cmap=color_map)\n",
    "    handles, _ = scatter.legend_elements(prop=\"colors\")\n",
    "    plt.legend(handles, unique_labels, title=\"Labels\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 2.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f7a49",
   "metadata": {},
   "source": [
    "#### Oppgave 2.2 – Tekstbesvarelse\n",
    "*Hva ser du på plottene?* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0bc31d",
   "metadata": {},
   "source": [
    "### Oppgave 2.3 – Vekting (3 poeng)\n",
    "\n",
    "For å få bedre representasjoner kan det være lurt å vekte de ulike dimensjonene/trekkene ulikt, slik at de trekkene som er mer informative gis høyere vekt. Her skal dere bruke en type vekting kalt _term frequency–inverse document frequency (TF-IDF)_.\n",
    "\n",
    "Scikit-learn har en innebygd klasse for TF-IDF kalt `TfidfTransformer` som dere skal bruke. Den tar dokumentvektorer fra `CountVectorizer` som input og gir ut nye, vektede vektorer som output.\n",
    "I likhet med `CountVectorizer` må denne tilpasses treningssettet med `.fit()` før vi kan ta den i bruk. Dette er for å få gjort de nødvendige frekvenstellingene i dokumentene.\n",
    "\n",
    "I denne oppgaven skal dere:\n",
    "\n",
    "- Lage en TF-IDF-vektet representasjon av dokumentene\n",
    "- Visualisere de vektede vektorene med `scatter_plot()`. Ser dere noen forskjell på resultatet sammenlignet med det dere fikk uten TF-IDF-vekting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d971d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37dc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 2.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e3674b",
   "metadata": {},
   "source": [
    "#### Oppgave 2.3 – Tekstbesvarelse\n",
    "*Ser du noen forskjell mellom vektorene med og uten tf-idf?* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd62a51",
   "metadata": {},
   "source": [
    "## Oppgave 3 – Klassifisering med *k*-NN\n",
    "\n",
    "Nå er vi klare for å lage en klassifikator. Klassifikatoren skal la oss predikere hvilken kategori et gitt dokument tilhører.\n",
    "For å gjøre dette skal vi bruke `KNeighborsClassifier` fra scikit-learn som baserer seg på _k_-NN-algoritmen.\n",
    "\n",
    "Klassifikatoren trenes med `.fit()`, der vi sender inn treningsdataene. Etter dette kan vi predikere med `.predict()` på validerings- og testdata.  \n",
    "For best resultat er det viktig at dataene vi trener med og de vi ønsker å predikere, er preprosessert på samme måte. For eksempel vil en klassifikator trent på data uten TF-IDF-vekting gi dårlige resultater for dokumentvektorer med TF-IDF.\n",
    "\n",
    "\n",
    "For å måle hvor godt klassifikatoren klarer å klassifisere de ulike dokumentene kan vi bruke _nøyaktighet_ (engelsk: _accuracy_), som regnes ut basert på hvor mange vi klarte å predikere korrekt, delt på antall vi forsøkte å predikere totalt.\n",
    "\n",
    "For å regne ut dette kan dere bruke funksjonen `accuracy_score()` fra scikit-learn, som tar inn to lister: først en liste de korrekte merkelappene til dataene, så en liste med merkelapper som klassifikatoren har predikert.\n",
    "\n",
    "Alternativt kan vi bruke $F_{1}$-_mål_ (engelsk: $F_{1}$-_score_), som er et gjennomsnitt mellom _presisjon_ (engelsk: _precision_) og _sensitivitet_ (engelsk: _recall_). Dette kan vi regne ut ved å bruke `f1_score()` fra scikit-learn.  \n",
    "Denne tar også inn de to listene som parametere, men siden vi her jobber med flere klasser, må vi endre parameteren `average` som spesifiserer hvordan snittet mellom klassene skal regnes ut. Her kan den settes til `'macro'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9b686",
   "metadata": {},
   "source": [
    "### Oppgave 3.1 – _k_-NN (3 poeng)\n",
    "\n",
    "Lag en instans av `KNeighborsClassifier` der k = 1. Tren denne på treningsdataene (med TF-IDF-vekting) og gjør prediksjoner på valideringsdataene. Vis resultatene for både `accuracy_score()` og `f1_score()`. Gjør så det samme med en instans der k = 5000. \n",
    "\n",
    "Rapporter resultatene i en markdown-celle, der dere også skriver kort om hvordan disse resultatene kan knyttes til over- og undertilpasning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e99c8",
   "metadata": {},
   "source": [
    "#### Oppgave 3.1 – Tekstbesvarelse\n",
    "\n",
    "_Rapporter resultatene og knytt de opp mot over- og undertilpasning._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929214b0",
   "metadata": {},
   "source": [
    "### Oppgave 3.2 – Hyperparametertilpassing (5 poeng)\n",
    "\n",
    "I _k_-NN er _k_ en hyperparameter. Ved å endre på verdien av _k_ vil vi få ulike resultater fra klassifikatoren.\n",
    "Hvilken _k_-verdi som passer best er avhengig av datasett, preprosessering og vekting. Vi må derfor bare prøve oss fram til vi finner passende verdier.\n",
    "\n",
    "I denne oppgaven skal vi prøve en rekke _k_-verdier for å se hva som gir best resultat.\n",
    "\n",
    "Når dere skal finne den beste _k_-verdien, skal dere bruke valideringssettet.\n",
    "\n",
    "Lag ei løkke som trener en _k_-NN-klassifikator for forskjellige verdier av _k_ fra 1 til 20.\n",
    "For hver _k_-verdi skal dere teste både dataene med TF-IDF-vekting og dataene uten, og beregne enten nøyaktighet eller $F_1$-mål for hver av dem. Hvilket av målene dere bruker velger dere selv, men dere må skrive minst to setninger om hvilke fordeler og ulemper de to målene har. \n",
    "\n",
    "Lag en tabell der dere inkluderer resultatene deres og beskriv kort hva dere observerer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ab787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 3.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee9bf0",
   "metadata": {},
   "source": [
    "#### Oppgave 3.2 – Tekstbesvarelse\n",
    "\n",
    "_Inkluder en tabell og diskuter resultatene. Hva er styrkene og svakhetene til henholdsvis nøyaktighet og $F_1$-mål?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ebbdc",
   "metadata": {},
   "source": [
    "### Oppgave 3.3 – Testing (4 poeng)\n",
    "\n",
    "Dere skal nå ha funnet den kombinasjonen av _k_-verdi og representasjon (vektet/ikke-vektet) som oppnår best nøyaktighet på valideringssettet.  \n",
    "I denne oppgaven skal dere se hvor godt denne verdien fungerer på testsettet. Testsettet skal være data som klassifikatoren ikke har \"sett\" før, hverken under trening eller under hyperparametertilpassing.\n",
    "\n",
    "Dere skal nå trene en _k_-NN-klassifikator med den beste kombinasjonen av _k_-verdi og representasjon fra oppgave 3.2. Dere skal så gjøre prediksjoner på valideringssettet. For disse prediksjonene skal dere rapporterte:\n",
    "\n",
    "- Nøyaktighet\n",
    "- $F_1$-mål\n",
    "- Presisjon\n",
    "  - Gjøres med `precision_score()`. Denne tar samme parametere som `f1_score()`.\n",
    "- Sensitivitet\n",
    "  - Gjøres med `recall_score()`. Denne tar samme parametere som `f1_score()`.\n",
    "\n",
    "Gjør deretter prediksjoner for det testsettet og rapporter de samme metrikkene. Hvordan er ytelsen på testsettet sammenlignet med valideringssettet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 3.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ef2e0",
   "metadata": {},
   "source": [
    "#### Oppgave 3.3 – Tekstbesvarelse\n",
    "\n",
    "_Hva ser dere av resultatene på testsettet?_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in1160",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
