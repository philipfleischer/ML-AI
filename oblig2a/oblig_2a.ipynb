{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dde2bab",
   "metadata": {},
   "source": [
    "# Oblig 2a – Lineær og logistisk regresjon\n",
    "\n",
    "**Våren 2026**\n",
    "\n",
    "Det er en god idé å lese gjennom hele oppgavesettet før dere setter i gang. Dersom dere har spørsmål så kan dere:\n",
    "\n",
    "- gå i gruppetime,\n",
    "- spørre på Discourse\n",
    "- eller sende epost til in1160-hjelp@ifi.uio.no dersom alternativene over av en eller annen grunn ikke passer for spørsmålet.\n",
    "\n",
    "## Innlevering\n",
    "\n",
    "Oppgaven leveres innen 11. mars klokken 23.59 i [Devilry](https://devilry.ifi.uio.no/).\n",
    "\n",
    "Innleveringen skal bestå av én Jupyter notebook med både kode og tilhørende forklaringer. Før innlevering skal du kjøre gjennom hele notebooken, før du lagrer siste gang. Den bør kjøre uten å feile og vise alt som skal være med.\n",
    "\n",
    "Vi understreker at innlevering av kode alene ikke er nok for å bestå oppgaven – vi forventer at notebooken også skal inneholde kommentarer (på norsk eller engelsk) på hva dere har gjort og begrunnelser for valgene dere har tatt underveis. La enhver oblig bli en trening i å formidle forskning. Bruk helst hele setninger, og matematiske formler om nødvendig. Resultater skal presenteres i tabeller på en oversiktlig måte. Det å forklare med egne ord, bruke begreper vi har gått gjennom på forelesningene og å forklare og reflektere over løsningene deres er en viktig del av læringsprosessen – ta det på alvor!\n",
    "\n",
    "Når det gjelder bruk av generative prateroboter (ChatGPT og lignende): Dere kan bruke dem som en \"sparringspartner\", for eksempel for å forklare noe dere ikke helt har forstått. Dere har imidlertid ikke lov til å bruke dem til å generere løsninger (enten delvis eller fullstendig) til noen av oppgavene. Funksjoner for automatisk skriving av kode, som Copilot i VS Code, må derfor også være deaktivert mens dere jobber på obligen.\n",
    "\n",
    "Bruker dere KI-verktøy vil vi også at dere kort beskriver hvordan dere har brukt dem under arbeidet med oppgaven.\n",
    "\n",
    "Det er ikke mulighet for omlevering av obliger som ikke bestås.\n",
    "\n",
    "**Poeng:** Obligen gir maksimalt 25 poeng og 6 bonuspoeng. For å bestå kreves det totalt 30 av 50 poeng fra oblig 2a og 2b tilsammen. Bonuspoengene telles ikke med i denne beregningen. Poengfordelingen er markert i overskriften til oppgaven, der `p` indikerer vanlig poeng og `b` indikerer bonuspoeng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15bbaa",
   "metadata": {},
   "source": [
    "\n",
    "## Bakgrunn\n",
    "\n",
    "I denne obligen skal vi jobbe med lineær og logistisk regresjon. Disse modellene er noen av de nyttigste maskinlæringsmodellene som finnes, der lineær regresjon blir brukt for *regresjon* og logistisk regresjon blir brukt til *klassifikasjon*. Oppgavene går ut på å først bli kjent med datasetene som blir brukt, og deretter implemetere litt funksjonalitet som tapsfunksjoner og prediksjon med modellene. For å slippe å implementere treningen av modellene skal vi bl.a. bruke modeller fra biblioteket `sklearn` til å trene på datasetene. Til slutt skal resultatet tolkes og det gjøres også litt trekk-seleksjon (feature selection).\n",
    "\n",
    "Obligen er delt opp i mange mindre deloppgaver og det følger med tester for alle implementasjonsoppgavene. Testene printer ut feilmeldinger dersom testen feiler, og printer ikke ut noe om testen bestås (med mindre dere sender med argumentet `message_on_pass=True`). Feilmeldingene sjekker for flere typer feil, som feil returverdi, feil utregning, error under kjøring og liknende, så det kan være nyttig å lese feilmeldingen for å hjelpe til med implementeringen av oppgavene. Testene må bestås for at oppgavene skal bli godkjent, men beståtte tester garanterer ikke at implementasjonen er korrekt.\n",
    "\n",
    "Oppgavene skal implementeres med NumPy og klassene `LinearRegression` og `LogisticRegression` fra `sklearn`. Det er ikke tillatt å importere funksjoner som gjør det oppgaven ber dere om å implementere, for eksempel å bruke `accuracy_score` fra `sklearn` for å implementere `calculate_accuracy`.\n",
    "\n",
    "Vi starter med å importere de nødvendige bibliotekene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c70df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "from tests2a import (\n",
    "    test_calculate_accuracy,\n",
    "    test_calculate_bce,\n",
    "    test_calculate_mse,\n",
    "    test_predict_linear_regression,\n",
    "    test_predict_logistic_regression,\n",
    "    test_sigmoid,\n",
    ")\n",
    "from utils2a import get_auto_mpg_data, get_spambase_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09846563",
   "metadata": {},
   "source": [
    "## 1 - Lineær regresjon [Totalt 12p og 3b]\n",
    "\n",
    "### 1.0 - Bakgrunn og dataset [2p, 1b]\n",
    "\n",
    "Lineær regresjon er en enkel, men effektiv, regresjonmodell. Modellen predikerer et reelt tall (fra minus uendelig til pluss uendelig) gitt en liste med inputtrekk (features). Ved å bruke et datasett som inkluderer både input og tilhørende fasitverdier kan vi finne koeffisientene som minimerer forskjellen mellom prediksjonene og fasitverdiene.\n",
    "\n",
    "Vi starter med å se på datasettet vårt. Vi skal bruke [`Auto MPG` datasettet](https://people.math.carleton.ca/~smills/2013-14/DataMining/Data/UCI%20Machine%20Learning%20Repository%20%20Auto%20MPG%20Data%20Set.htm), som er et mye brukt og konseptuelt relativt enkelt datasett for regresjon. Det inneholder informasjon om biler fra 70- og 80-tallet, som blir brukt til å predikere hvor bensineffektive bilene er, målt i *miles per gallon* (mpg). Vi skal først jobbe med to trekk: `weight`, som er vekten til bilene, og `acceleration`, som er hvor rask bilene kan akselerere. Litt senere i obligen vil vi inkludere flere trekk fra datasettet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b3998",
   "metadata": {},
   "source": [
    "La oss først avklare notasjonen litt: Vi bruker $n$ til å notere antall datapunkter i datasettet, som er 398 for datasettet vårt, eller 392 etter at vi har fjernet datapunkter med manglende verdier. Hvert av datapunktene har input $\\textbf{x}$ og sann verdi (target) $y$. Dette vil si vi har to lister av lengde $n$, input $\\textbf{x}_1, \\textbf{x}_2, ..., \\textbf{x}_n$ og de sanne verdiene $y_1, y_2, ..., y_n$. Merk at input $\\textbf{x}$ er notert med **fet skrift**, som representerer en vektor med flere tall. Vi starter med $p = 2$ antall trekk, som for bil nummer $i$ notert ved $\\textbf{x}_i = (x_{i, 1}, x_{i, 2})$, der $x_{i, 1}$ representerer vekten til bil nummer $i$ og $x_{i, 2}$ representerer bil nummer $i$ sin akselerasjon. Vi bruker ofte indeksen $i$ til å representere et *vilkårlig* tall, som her kan betegne et tall mellom 1 og $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbadfa7",
   "metadata": {},
   "source": [
    "Vi starter med å laste inn datasettet. Datasettet blir lest med biblioteket `seaborn`. Dere skal ikke endre på noen av argumentene i funksjonen under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab33e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_data = get_auto_mpg_data(\n",
    "    columns_to_include=[\"weight\", \"acceleration\"],\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    perform_scaling=False,\n",
    ")\n",
    "x_train = mpg_data[\"x_train\"]\n",
    "y_train = mpg_data[\"y_train\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8d90b",
   "metadata": {},
   "source": [
    "**Merk**: Dataen over er ikke skalert (fra keyword argumentetet `perform_scaling=False`). Dette er for å bli bedre kjent med dataen i menneskelige lesbare måleenheter. Når vi bruker dataen til å trene og predikere senere er det viktig at dataen blir skalert, ved å gi inn argumentet `perform_scaling=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a86c88",
   "metadata": {},
   "source": [
    "Objektet som blir returnert, `mpg_data`, er en Python ordbok (dictionary) med trenings-, validerings- og testdatasplitter, samt navn på trekkene. Som vanlig kommer vi til å trene modellen med treningsdataene, bruke evalueringsdataene til å finne ut hvilke treningskonfigurasjoner som fungerer best, og spare testdataene helt til slutt for å gjøre et estimat på hvor bra modellen vår vil fungere. Til å begynne med skal vi kun se på treningsdataene.\n",
    "\n",
    "Input-dataene, gitt ved `mpg_data[\"x_train\"]`, er et to-dimensjonalt NumPy array. Radene representerer ulike datapunkter og kolonnene forskjellige trekk. Dere kan indeksere rad $i$ og kolonne $j$ med `x_train[i, j]`. NumPy-indeksering har mange nyttige funksjoner. I tillegg til å indeksere en enkel verdi, kan man *slice* en delmengde av arrayen. For å få kolonne nummer 1 for rad 3 til rad 8 kan man for eksempel bruke `x_train[3:9, 1]`, og for å få kolonne 0 for alle radene kan man bruke `x_train[:, 0]`. \n",
    "\n",
    "La oss gjøre noen oppgaver for å bli kjent med datasettet og NumPy-indeksering. Alle oppgavene forholder seg til treningsdatasplitten for Auto MPG og indeksering starter på 0. Alle svarene kan finnes ved NumPy-indeksering og funksjoner uten looping. Print ut svarene på et lesbart og pent format. Verdien til `mpg_data[\"features_names\"]` har navn tilsvarende kolonnene i x-dataene (her er `weight` den nulte kolonnen og `acceleration` den første). Måleenhenten til vekt er \"pounds\" og måleenheten til akselerasjonen er antall sekunder bilen bruker på 0 til 60 \"miles per hour\".\n",
    "\n",
    "**Oppgave 1.0**: \n",
    "\n",
    "- a) Hvor mye veier bil nummer 3?\n",
    "- b) Hva er akselerasjonen til bil nummer 100?\n",
    "- c) Hva er gjennomsnittlig vekt for bilene og gjennomsnittlig akselerasjon?\n",
    "- d) Hva er det høyeste og laveste bensinforbruket (oppgitt i \"miles per gallon\")?\n",
    "- e) (*Bonus*) Hva er gjennomsnittlig bensinforbruk for bilene som veier mer enn 3000 pounds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f1693",
   "metadata": {},
   "source": [
    "(Skriv svarene dine her)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cfcf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto MPG - Train split:\n",
      "--------------------------------------------------\n",
      "a) Car 3 weight:            4380.0 pounds\n",
      "b) Car 100 acceleration:    15.40 seconds\n",
      "\n",
      "c) Average (mean) weight:   2965.1 pounds\n",
      "   Average (mean) accel:    15.61 seconds\n",
      "\n",
      "d) Max miles per gallon:    46.60 miles/gallon\n",
      "   Min miles per gallon:    9.00 miles/gallon\n",
      "\n",
      "e) Mean mpg (weight>3000):  17.11 miles/gallon\n",
      "   Count (weight>3000): 98 cars\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train er allerede lastet inn fra mpg_data\n",
    "# x_train = mpg_data[\"x_train\"]\n",
    "# y_train = mpg_data[\"y_train\"]\n",
    "\n",
    "# Oppgave 1.0 a) Hvor mye veier bil nummer 3?\n",
    "# rad 3 sin kolonne plass 0 representerer bil 3 sin vekt\n",
    "# x_train er en 2D-array med shape(N, 2): kolonne 0=weight(pounds) og kolonne 1=acceleration (0-60mph)\n",
    "car_3_weight = x_train[3, 0]\n",
    "\n",
    "# Oppgave b) Hva er akselerasjonen til bil nummer 100?\n",
    "# rad 100 sin kolonne plass 1 representerer bil 100 sin akselerasjon\n",
    "car_100_accel = x_train[100, 1]\n",
    "\n",
    "# Oppgave c) Hva er gjennomsnittlig vekt for bilene og gjennomsnittlig akselerasjon?\n",
    "# Gjennomsnittlig vekt er: alle radene (alle bilene) sine første kolonne (vekter); .mean()\n",
    "mean_weight = x_train[:, 0].mean()\n",
    "# Gjennomsnittlig akselerasjon for alle biler: alle radene og dem andre kolonnen (akselerasjonsverider); .mean()\n",
    "mean_accel = x_train[:, 1].mean()\n",
    "\n",
    "# Oppgave d) Hva er det høyeste og laveste bensinforbruket (oppgitt i \"miles per gallon\")?\n",
    "# y_train er en 1D-array med mpg (miles per gallon)\n",
    "max_mpg = y_train.max()\n",
    "min_mpg = y_train.min()\n",
    "\n",
    "# Oppgave e) Hva er gjennomsnittlig bensinforbruk for bilene som veier mer enn 3000 pounds?\n",
    "# x_train[:, 0] gir alle vektene (kolonne 0 = weight)\n",
    "# Så sammenligner vi hver vekt med 3000 -> gir en boolsk array med True/False, dette kalles en boolsk maske.\n",
    "heavy_3000 = x_train[:, 0] > 3000\n",
    "# y_train inneholder mpg-verdiene, og rad med indeks \"i\" i x_train matcher samme rad i y_train. Når vi så bruker den boolske masken fra x_train på y_train: y_train[heavy_3000], så får vi kun mpg-verdiene for biler som veier mer enn 3000 pounds.\n",
    "# Til slutt tar vi gjennomsnittet (mean) av disse mpg-verdiene\n",
    "mean_3000_mpg = y_train[heavy_3000].mean()\n",
    "\n",
    "# Her er fine prints:\n",
    "print(\"Auto MPG - Train split:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"a) Car 3 weight:            {car_3_weight:.1f} pounds\")\n",
    "print(f\"b) Car 100 acceleration:    {car_100_accel:.2f} seconds\")\n",
    "print()\n",
    "print(f\"c) Average (mean) weight:   {mean_weight:.1f} pounds\")\n",
    "print(f\"   Average (mean) accel:    {mean_accel:.2f} seconds\")\n",
    "print()\n",
    "print(f\"d) Max miles per gallon:    {max_mpg:.2f} miles/gallon\")\n",
    "print(f\"   Min miles per gallon:    {min_mpg:.2f} miles/gallon\")\n",
    "print()\n",
    "print(f\"e) Mean mpg (weight>3000):  {mean_3000_mpg:.2f} miles/gallon\")\n",
    "print(f\"   Count (weight>3000): {heavy_3000.sum()} cars\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc3d0e",
   "metadata": {},
   "source": [
    "### 1.1 - Gjennomsnittlig kvadratfeil (mean squared error) [2p]\n",
    "\n",
    "Modellen finner verdien på koeffisienten ved å minimere feilen på treningsdataene. Feilen måles mellom prediksjonene $\\hat{\\textbf{y}}$ (uttalt *y-hatt*) og fasitverdiene $\\textbf{y}$.\n",
    "\n",
    "Det er generelt mange måter å måle feil og forskjeller på, men for lineær regresjon bruker man som regel *gjennomsnittlig kvadratfeil*, som regel kalt *mean squared error* (MSE). Dette måler altså den gjennomsnittlige kvadratiske forskjellen mellom prediksjonene og fasitverdiene, altså:\n",
    "\n",
    "$$\\text{MSE}(\\textbf{y}, \\hat{\\textbf{y}}) = \\frac{1}{n} \\sum_{i = 0}^n (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**Notasjon**: Symbolet $\\Sigma$ er den store greske bokstaven *sigma*, som representerer en sum. Her blir $\\sum_{i = 0}^n (y_i - \\hat{y}_i)^2 = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + ... + (y_n - \\hat{y}_n)^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e83a73",
   "metadata": {},
   "source": [
    "**Vektorisering:** Hele obligen kan løses enten med eller uten vektorisering. Vektorisering handler om å la lavnivå-biblioteker som NumPy håndtere iterering (løkker), istedenfor å loope eksplisitt i Python. Vektorisering gir mye raskere kode, siden itereringen skjer i C istedenfor Python, i tillegg til at bibliotekene kan håndtere passende datastrukturer, minneallokering og parallelisering. Koden blir også mer kortfattet, siden man kan erstatte løkker med funksjonskall. Dette kan både gjøre koden mer lesbar, men også føre til at det er vanskeligere å forstå hva koden egentlig gjør. Dere kan selv velge om dere vil bruke NumPy funksjoner (som `np.square()`, `np.mean()`, vektorprodukt og matrisemultiplikasjon) eller om dere vil iterere eksplisitt. Det er også mulig å vektorisere deler av koden, eller først skrive koden med løkker og deretter erstatte den med vektorisert kode. Dette er en god måte å lære å skrive effektiv kode og bedre forstå hva de vektoriserte funksjonene gjør."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe6525",
   "metadata": {},
   "source": [
    "### Notater\n",
    "Hva betyr MSE og hva står de forskjellige delen av formeln av:\n",
    "- y_i står for den ekte verdien.\n",
    "- y-hatt_i står for den predikerte verdien.\n",
    "- (y_i - y-hatt_i) er feil-verdien.\n",
    "- Vi kvadrerer feilen, som gjør den positiv og også straffer større feil mer enn små feil.\n",
    "- Summerer alle feilene.\n",
    "- Deler på antall datapunkter: n.\n",
    "Altså:\n",
    "- MSE = Gjennomsnittet av de kvadrerte feilene som oppstår.\n",
    "\n",
    "MSE må:\n",
    "- Returnere en float.\n",
    "- Fungere for NumPy-arrays\n",
    "- Fungere uten loops (i oblig tilfelelt her hvertfall).\n",
    "- Ikke bruke sklearn-funksjoner (--||--)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c4b9f",
   "metadata": {},
   "source": [
    "**Oppgave 1.1**: Implementer funksjonen `calculate_mse()`, som tar to arrayer av samme lengde og regner ut og returnerer MSE-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d096b7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_mse(y_data, predictions):\n",
    "    \"\"\"\n",
    "    Calculates and returns the mean squared error (MSE).\n",
    "    Except two arrays of the same length as input.\n",
    "\n",
    "    Args:\n",
    "        y_data (np.array): The true values as an array of numbers.\n",
    "        predictions (np.array): The predictions as an array (of same length as `y_data`) of numbers.\n",
    "\n",
    "    Returns:\n",
    "        float: Value corresponding to the MSE.\n",
    "    \"\"\"\n",
    "    # God praksis å sjekke om input argumentene har lik lengde\n",
    "    if len(y_data) != len(predictions):\n",
    "        raise ValueError(\"y_data and predictions must have the same lenght!\")\n",
    "\n",
    "    # Vi kalkulerer residualene (feil-verdiene).\n",
    "    # residuals er forskjellen mellom de sanne og predikerte verdiene\n",
    "    residuals = y_data - predictions\n",
    "\n",
    "    # Vi kvadrerer residual-verdiene, slik at alle verdiene er positive og store feil straffes hardere. Hvis vi ikke kvadrer dem så vil positive og negative verdier kansellere hverandre ut.\n",
    "    squared_residuals = residuals**2\n",
    "\n",
    "    # Finner mean squared verdier for errors, som da er: MSE\n",
    "    mse = np.mean(squared_residuals)\n",
    "\n",
    "    return mse\n",
    "\n",
    "y_true = np.array([2, 4, 6])\n",
    "y_predicated = np.array([1, 5, 7])\n",
    "\n",
    "# Expected:\n",
    "# (2-1)^2 = 1\n",
    "# (4-5)^2 = 1\n",
    "# (6-7)^2 = 1\n",
    "# MSE = (1 + 1 +1)/3 = 1\n",
    "\n",
    "print(calculate_mse(y_true, y_predicated))\n",
    "\n",
    "test_calculate_mse(input_function=calculate_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ef2f2",
   "metadata": {},
   "source": [
    "**Tester**: Obligen inneholder testfunksjoner lagret i `test2a.py` som dere kan bruke til å teste implementasjonene deres. Beståtte tester vil ikke garantere at det ikke er noen som er feil, men dersom noen av testene feiler er det sikkert at noe ikke er riktig. Testene er importert og kalt i prekoden. De tar inn funksjonen de skal teste som argument og itererer over flere test-tilfeller. Dersom testene bestås vil de av konvensjon ikke gi noen output, men dersom dere har lyst på en bekreftelse at testene bestod kan dere sende med argumentet `message_on_pass=True`. Dere står også fritt til å prøve funksjonene selv og lage egne tester, men pass på at den endelige besvarelsen ikke inneholder for mye kode som ikke er direkte svar på oppgaven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa57be8",
   "metadata": {},
   "source": [
    "### 1.2 - Prediksjon [2p]\n",
    "\n",
    "Vi kan nå implementere prediksjon for lineær regresjon. La oss starte med å visualisere lineær regresjon med figuren under.\n",
    "\n",
    "<!-- markdownlint-disable-next-line MD033 -->\n",
    "<img src=\"bilder/linear_regression_general_formula.png\" alt=\"Linear regression diagram\" width=\"600\"/>\n",
    "\n",
    "Modellen får $\\textbf{x}$ som input og gir en prediksjon av den sanne verdien som output, notert ved $\\hat{y}$. Med datasettet vårt får den altså bilenes vekt og akselerasjon som input og bruker dette til å predikere hvor mye bensin den bruker. Dette gjør den ved å gange inputet med *vekter* og plusse på et *konstantledd* (også kalt bias). For lineære modeller er vektene og konstantleddet ofte kalt *koeffisienter*, og vi bruker den grenske bokstaven $\\beta$ (uttalt *beta*) til å representere dem. For et datapunkt $i$, vil modellen vår altså regne ut prediksjonen $\\hat{y}_i = \\beta_1 x_{i, 1} + \\beta_2 x_{i, 2} + \\beta_0$. Her er altså $\\beta_1$ og $\\beta_2$ vektene (eller koeffisientene) til henholdsvis bilenes vekt og akselerasjon, mens $\\beta_0$ er konstantleddet (biaset). Koeffisientene er altså tall som blir ganget med inputet, som også er tall, og plusset sammen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23083a",
   "metadata": {},
   "source": [
    "La oss implementere prediksjonen for lineær regresjon i en funksjon.\n",
    "\n",
    "**Oppgave 1.2**: Implementer `linear_regression_predict()`. Funksjonen tar to argumenter, inputdataene og koeffisientene, og returnerer prediksjonene. Inputdataene er her en to-dimensjonal array av størrelse $[n, p]$, altså $n$ rader og $p$ kolonner, der hver rad tilsvarer et datapunkt og hver kolonne tilsvarer et trekk. Koeffisientene blir representert av en array med $p + 1$ verdier, der den nulte verdien er konstantleddet, mens elementet på indeks 1 er vekten for det første trekket, elementet på indeks 2 er vekten til det andre trekket, og så videre. Koeffisientene blir brukt på alle $n$ datapunktene og returnerer en array av lengde $n$ med tilsvarende prediksjoner.\n",
    "\n",
    "Her er det forskjellige muligheter med hensyn på vektorisering. Vi må lage to (implisitte eller eksplisitte) løkker: en over datapunktene og en over trekkene. Det er mulig å vektorisere begge disse løkkene, man dere kan også iterere eksplisitt over begge, eller gjøre en kombinasjon. For best læringsutbytte kan det være lurt å første iterere eksplisitt og så prøve å erstatte det med vektorisert kode. Operatoren `@` kan brukes som matrisemultiplikasjon med NumPy-arrayer og `np.dot()` kan brukes for å få prikkproduktet, der `np.dot(a, b)` tilsvarer $\\sum_{i=1}^n a_1 \\cdot b_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8f45c",
   "metadata": {},
   "source": [
    "### Notater\n",
    "\n",
    "Lineær regresjon delt opp:\n",
    "\n",
    "Beta = B\n",
    "- B_0 = bias (konstantledd)\n",
    "- B_1 ... B_p = vektene.\n",
    "- x_ij er feature j for datapunkt i.\n",
    "- y-hatt_i er prediksjon for datapunkt i.\n",
    "\n",
    "Dette skal implementeres for alle datapunktene samtidig.\n",
    "\n",
    "#### x_data @ weights:\n",
    "Hvis vi har:\n",
    "- x_data = [n, p]\n",
    "- weights = [p]\n",
    "så:\n",
    "- x_data @ weights\n",
    "gi følgende:\n",
    "- For hver rad i x_data så multipliserer vi hver feature med tilhørende vekt og summerer til slutt alt sammen, NumPy gjør dette for oss for alle radene samtidig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da447b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.  -11.5]\n"
     ]
    }
   ],
   "source": [
    "def linear_regression_predict(x_data, coefficients):\n",
    "    \"\"\"\n",
    "    Given input data `x_data` of shape [n, p] (`n` datapoints and `p` features)\n",
    "    and `coefficients` of shape [p + 1], returns the predictions the model\n",
    "    gives as an [n]-length array.\n",
    "\n",
    "    Args:\n",
    "        x_data (np.array): [n, p]-shaped array of input data.\n",
    "        coefficient (np.array): [p + 1]-shaped array of coefficient. Element number\n",
    "            zero corresponds to the bias while element one to p corresponds to\n",
    "            the weight for feature 1 to p.\n",
    "\n",
    "    Returns:\n",
    "        np.array: [n]-shaped data of corresponding predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sjekker at x_data er 2-dimensjonal med n datapunkter og p features. ndim = Number of Dimensions\n",
    "    if x_data.ndim != 2:\n",
    "        raise ValueError(\"x_data must be a 2D array with shape [n, p]!\")\n",
    "\n",
    "    # Henter ut antall datapunkter n og antall features p\n",
    "    n, p = x_data.shape\n",
    "\n",
    "    # Vi må ha p+1 koeffisienter, der det er 1 bias + 1 vekt per feature\n",
    "    if len(coefficients) != p + 1:\n",
    "        raise ValueError(f\"coefficients must have length p + 1 = {p+1}, but got {len(coefficients)}!\")\n",
    "\n",
    "    # Første element i koeffisientene er bias, altså konstantleddet\n",
    "    bias = coefficients[0]\n",
    "\n",
    "    # Resten av elementene i koeffisientene er vektene til feature 1...p\n",
    "    weights = coefficients[1:]\n",
    "\n",
    "    # Vi behandler det matematisk slik:\n",
    "    # predictions = bias + X * weights\n",
    "    # x_data @ weights betyr: for hver rad i x_data:\n",
    "        # Regn ut prikkproduktet (dot) mellom raden og weights\n",
    "    # Resultatet blir da et array med én verdi per datapunkt med shape [n].\n",
    "    predictions = bias + (x_data @ weights)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# eget mini eksempel\n",
    "x = np.array([\n",
    "    [10, 2],\n",
    "    [3, 7]\n",
    "])\n",
    "\n",
    "coefficients_2 = np.array([1, 0.5, -2])\n",
    "# bias = 1\n",
    "# weight1 = 0.5\n",
    "# weight2 = -2\n",
    "\n",
    "# Første rad:\n",
    "# y = 1 + 0.5 * 10 + (-2)*2 = 2\n",
    "# Andre rad:\n",
    "# y = 1 + 0.5 * 3 + (-2)*7 = -11.5\n",
    "\n",
    "print(linear_regression_predict(x, coefficients_2))\n",
    "\n",
    "test_predict_linear_regression(input_function=linear_regression_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c37eb",
   "metadata": {},
   "source": [
    "### 1.3 - Kjøring og evaluering av lineær regresjon [2p]\n",
    "\n",
    "Vi skal nå bruke maskinlæringsbiblioteket `sklearn`, og mer spesifikt klassen `LinearRegression`, til å trene en regresjonsmodell på datasettet vårt. Modellen kan initialiseres med `model = LinearRegression()`. Deretter kan den trenes ved å kalle `model.fit(X=x_train, y=y_train)`, som vil finne koeffisientene som gjør prediksjonene for treningsdataen `x_train` så lik de sanne verdiene `y_train` som mulig. Deretter kan man bruke modellen til å predikere med `model.predict(X=x_val)`.\n",
    "\n",
    "**Oppgave 1.3**: Tren modellen på treningsdataene og prediker $\\hat{y}$-verdier for valideringsdataene. Bruk så `calculate_mse` til å regne ut gjennomsnittlig kvadratfeil mellom disse prediksjonene og de sanne verdiene i `y_val`. Rapporter resultatet på et leselig format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63a5dadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lineaer Regression (sklearn) - Evaluation\n",
      "--------------------------------------------------\n",
      "Training set: n=235, p=2\n",
      "Value set: n=78, p=2\n",
      "\n",
      "Intercept (B_0): 23.7702\n",
      "Coefficients (B_1 ... B_p): [-6.24212917  0.99188927]\n",
      "\n",
      "Validation MSE value: 18.2651\n"
     ]
    }
   ],
   "source": [
    "# Laster inn Auto MPG-data med scaling aktivert. Siden perform-scaling=True, så betyr det at features blir skalert.\n",
    "# Grunnen til at dette er hensiktsmessig akkurat nå er at features som har store størrelser (f.eks: weight mellom 1000-5000 og acceleration mellom 8-25) ikke får for stor eller liten påvirkning i modellen som lages.\n",
    "mpg_data = get_auto_mpg_data(\n",
    "    columns_to_include=[\"weight\", \"acceleration\"],\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    perform_scaling=True,\n",
    ")\n",
    "\n",
    "# Dette er altså treningsdataen som brukes for å finne koeffisientene\n",
    "x_train = mpg_data[\"x_train\"]   # Shape blir her: [n, p]\n",
    "y_train = mpg_data[\"y_train\"]  # Shape blir her: [n]\n",
    "\n",
    "# Dette er valideringsdataen som brukes for å evaluere hvor bra modellen generaliserer\n",
    "x_val = mpg_data[\"x_val\"]  # Shape blir her: [n, p]\n",
    "y_val = mpg_data[\"y_val\"]  # Shape blir her: [n]\n",
    "\n",
    "# Her lager vi den lineære regresjonsmodellen fra sklearn.\n",
    "# LinearRegression() funksjonen i sklearn lærer en modeller av typen y-hatt, altså med bias + en lineær kombinasjon av feature.\n",
    "model = LinearRegression()\n",
    "\n",
    "# Nå trener vi modellen med fit().\n",
    "# model.fit(X, y) finner koeffisientene (beta-verdiene) som minimerer mse på treningssettet.\n",
    "# Notat: Dette kan løses med lineær algebra, men sklearn gjør det for oss nå.\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Nå som fit() er brukt, så har vi koeffisientene vi trenger:\n",
    "# - model.intercept = B_0 (bias)\n",
    "# - model.coef = [B_1, B_2, ..., B_p] (vektene)\n",
    "intercept = model.intercept_\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Nå predikerer vi på valideringsdataene.\n",
    "# Bruker modellen model til å lage prediksjoner y_hatt på x_value. Dermed blir output en 1D-array med samme lengde som y_value\n",
    "y_val_predicated = model.predict(x_val)\n",
    "\n",
    "# Nå evaluerer vi MSE på valideringssettet.\n",
    "# MSE måler jo gjennomsnittet kvadrert feil mellom fasiten som er y_val og de predikerte verdiene som er y_val_predicated\n",
    "mse_val = calculate_mse(y_val, y_val_predicated)\n",
    "\n",
    "# Printer svarene på en fin måte:\n",
    "print(\"Lineaer Regression (sklearn) - Evaluation\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Antall datapunkter og features vi har, der p = antall kolonner i x\n",
    "print(f\"Training set: n={x_train.shape[0]}, p={x_train.shape[1]}\")\n",
    "print(f\"Value set: n={x_val.shape[0]}, p={x_val.shape[1]}\")\n",
    "print()\n",
    "\n",
    "# Printer hvilke koeffisienter modellen finner, der Intercept = bias, Coef = vektene til de skalerte feature-ene\n",
    "print(f\"Intercept (B_0): {intercept:.4f}\")\n",
    "print(f\"Coefficients (B_1 ... B_p): {coefficients}\")\n",
    "print()\n",
    "\n",
    "# Endelige Resultatet\n",
    "print(f\"Validation MSE value: {mse_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e51843",
   "metadata": {},
   "source": [
    "### Tolkningsnotat av validerings resultatet for lineær regresjon med sklearn\n",
    "Modellen over er trent med LinearRegression() funksjonen på treningsdataene og har lært med dette:\n",
    "- y_hat = B_0 + B_1 * weight + B_2 * acceleration\n",
    "\n",
    "Siden perform_scaling=True, så er både weight og acceleration standardisert (med et typisk mean på 0 og standard deviation på 1). Dette betyr altså at koeffisientene representerer effekten per standardavviksverdi i stedet for: per originale enhet.\n",
    "\n",
    "Intercept B_0 = 23.77:\n",
    "Dette er altså modellens prediksjon når alle features er lik 0. Fordi dataene er skalert, betyr dette at bilen har en gjennomsnittlig vekt og akselerasjon, 23.77 er modellens estimerte mpg for en \"gjennomsnittlig bil\".\n",
    "\n",
    "B_1 weight = -6.24:\n",
    "Det at det er negativ verdi for beta 1, betyr at økt vekt gir lavere mpg. En økning på ett standardavvik i weight reduserer predikert mpg med 6.24, enklere sagt: tyngre biler bruker mer drivstoff.\n",
    "\n",
    "B_2 acceleration = 0.99:\n",
    "Det at verdien er positiv betyr at en høyere akselerasjonstid gir høyere mpg. Effekten for accel er mindre nn for weight, siden smp og drivstoffeffektive biler ofte akselerer tregere.\n",
    "\n",
    "Validation MSE = 18.27:\n",
    "Dette er gjennomsnittlig kvadrert feil på valideringssettet.\n",
    "RMSE (Root mse): sqrt(18.27) = 4.27\n",
    "Det betyr altså at modellen i snitt bommer med omtrent 4.3 mpg på nye valideringsdata.\n",
    "\n",
    "For å konkludere:\n",
    "Modellen fanger opp den sterke negative sammenhengen mellom vekt og drivstoffeffektivitet. Med bare to features gir modellen en rimelig feil, men den kan sannsynligvis forbedres ved å inkludere flere relevante trekk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41df3c",
   "metadata": {},
   "source": [
    "**Optimalisering av koeffisientene:** Når `.fit()` blir kalt blir koeffisientene satt til verdiene som minimerer MSE-en på treningsdatasplitten. Hvordan blir dette gjort? For lineær regresjon er det mulig å løse minimering av MSE som et likningsett av flere ukjente, der de ukjente er koeffisientene. Dette kan løses med grunnleggende lineær algebra, der den generelle løsningen kan uttrykkes som et enkelt regnestykke som bruker matrisemultiplikasjon og invertering. Her skiller lineær regresjon seg fra nesten alle andre maskinlæringsmodeller. Dersom modellen vår blir noe mer komplisert eller inkluderte veldig mange trekk, vil det ikke være mulig å uttrykke koeffisientene som minimerer tapet som et enkelt utrykk, og det brukes som regel iterative numeriske prosesser som *gradientnedstigning* (gradient descent) som det står et bonusavsnitt om i del 2.4 av denne obligen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1caa561",
   "metadata": {},
   "source": [
    "### 1.4 - Trekk-seleksjon (feature selection) [4p, 2b]\n",
    "\n",
    "Så langt har vi brukt bilenes vekt og akselerasjon til å predikere bensinforbruket, men det originale datasettet inneholder flere trekk som vi kan bruke. Det siste vi skal gjøre med lineær regresjon er å prøve forskjellige trekk. Dette kalles *trekk-seleksjon* (feature selection).\n",
    "\n",
    "Vi skal se på de fire følgende trekkene:\n",
    "- `horsepower`: Antall hestekrefter bilene har.\n",
    "- `model_year`: Året bilene ble produsert.\n",
    "- `cylinders`: Antall sylindere i motoren til bilene.\n",
    "- `displacement`: Volumet til motoren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ef495",
   "metadata": {},
   "source": [
    "**Oppgave 1.4.1**: Tren (på treningsdataene) og evaluer modellen (på valideringsdataene) med trekkene `horsepower` og `model_year` i tillegg til `weight` og `acceleration`. Hvordan forandrer dette resultatet? Prøv å forklare ved å resonnere over hva trekkene representerer og hvordan dette kan relatere til bensinforbruk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30e6a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 4 features, weight, acceleration, horsepower model year: \n",
      "--------------------------------------------------\n",
      "Validation mse: 10.6050\n",
      "intercept: 23.7702\n",
      "Coefficients: [-6.0397509   0.59775021  0.75835152  2.98764238]\n"
     ]
    }
   ],
   "source": [
    "# Henter data med de fire feature-ene\n",
    "# Legger til horsepower og model_year, i tillegg til weight og acceleration. perform_scaling=True gjør alle features standardizes der mean=0 og std=1.\n",
    "mpg_data = get_auto_mpg_data(\n",
    "    columns_to_include=[\"weight\", \"acceleration\", \"horsepower\", \"model_year\"],\n",
    "    perform_scaling=True,\n",
    ")\n",
    "x_train = mpg_data[\"x_train\"]\n",
    "y_train = mpg_data[\"y_train\"]\n",
    "x_val = mpg_data[\"x_val\"]\n",
    "y_val = mpg_data[\"y_val\"]\n",
    "\n",
    "# Trener modellen\n",
    "model = LinearRegression()\n",
    "\n",
    "# .fit() funksjonen brukes for å finne koeffisientene som minimerer mse på treningssettet.\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predikerer på valideringssettet\n",
    "y_val_predicated = model.predict(x_val)\n",
    "\n",
    "# Evaluerer med mse\n",
    "val_mse_4_features = calculate_mse(y_val, y_val_predicated)\n",
    "\n",
    "# Fin print av resultater\n",
    "\n",
    "print(\"Model with 4 features, weight, acceleration, horsepower model year: \")\n",
    "print(\"-\"*50)\n",
    "print(f\"Validation mse: {val_mse_4_features:.4f}\")\n",
    "print(f\"intercept: {model.intercept_:.4f}\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4703bf",
   "metadata": {},
   "source": [
    "### Resonnering 1.4.1:\n",
    "Sammenlignet med modellen med kun weight og acceleration som hadde en mse rundt 18, så har denne modellen med 4 features blitt bedre. Mse har nå gått ned til 10.61, dette betyr altså at prediksjonene på valideringsdataene er mer presise.\n",
    "\n",
    "Årsaken til forbedringen er åpenbart at vi nå har to ekstra trekk som er relevante for andel drivstoff bilene bruker.\n",
    "\n",
    "Horsepower er motorstyrken, der kraftigere motorer bruker mer drivstoff (generelt sett), og dette gir dermed modellen en mer presis informasjon enn kun vekten. \n",
    "\n",
    "Model_year kan gi oss en bedre teknologisk tankesett. Altså, nyere biler er ofte mer drivstoffeffektive sammenlignet med eldre biler, dette kan handler da om nyfinninger som gjør bilene mer effektive på mange forskjellige punkter.\n",
    "Koeffisienten på 2.99 betyr jo da at nyere biler i gjennomsnitt blir predikert med høyere mpg.\n",
    "\n",
    "Weight har fortsatt en negativ effekt på -6.04, på grunn av at tyngre biler bruker mer krefter. \n",
    "\n",
    "Konklusjonen er den at, ved å legge til horsepower og model_year så gir vi modellen mer relevant informasjon som reduserer valideringsfeil. Riktig trekk-seleksjon kan dermed forbedre modellens generaliseringsevne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c2a0f",
   "metadata": {},
   "source": [
    "**Oppgave 1.4.2**: Bruk nå `cylinders` og `displacement` i tillegg til de fire andre trekkene til å trene og evaluere modellen. Hvordan blir resultatet nå i forhold til de to forrige tilfellene? Vurder ulike forklaringer på hvorfor resultatet ble slik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1d82f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 6 features:\n",
      "--------------------------------------------------\n",
      "Validation mse: 11.6115\n",
      "Intercept: 23.7702\n",
      "Coefficients: [-0.25651233  1.49670839  0.57287724 -6.9591298   0.77038523  3.04278746]\n"
     ]
    }
   ],
   "source": [
    "# Nå henter vi data med alle de 6 feature-ene som finnes\n",
    "mpg_data = get_auto_mpg_data(\n",
    "    columns_to_include=[\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "        \"model_year\",\n",
    "    ],\n",
    "    perform_scaling=True,\n",
    ")\n",
    "x_train = mpg_data[\"x_train\"]\n",
    "y_train = mpg_data[\"y_train\"]\n",
    "x_val = mpg_data[\"x_val\"]\n",
    "y_val = mpg_data[\"y_val\"]\n",
    "\n",
    "# Trener modellen\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predikerer på valideringssettet\n",
    "y_val_predicated = model.predict(x_val)\n",
    "\n",
    "# Evaluerer mse\n",
    "val_mse_6_features = calculate_mse(y_val, y_val_predicated)\n",
    "\n",
    "# Pen utskrift for evalueringen av mse\n",
    "print(\"Model with 6 features:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Validation mse: {val_mse_6_features:.4f}\")\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374eab9e",
   "metadata": {},
   "source": [
    "### Resonnering 1.4.2:\n",
    "Når vi legger til cylinders og displacement features-ene i tillegg til de fire andre, så øker validation mse fra 10.6 til 11.6. Dette betyr at modellen faktisk blir dårligere på valideringsdataene.\n",
    "\n",
    "Cylinders og displacement er faktisk korrelert med weight og horsepower. Flere sylindere og større motorvolum har en sammenheng med høyere vekter og flere hestekrefter. Dette betyr at de nye trekkene ikke nødvendigvis gir oss ny informasjon, men heller overlappende.\n",
    "\n",
    "Grunnen til at dette er problematisk er at når flere sterkt korrelerte trekk brukes samtidig i en lineær modell, så kan det føre til noe som heter multikollinearitet. Dette gjør at koeffisientene er mer ustabile og kan dermed redusere modellens generaliseriger på nye data som kommer.\n",
    "\n",
    "Vi kan se at weight har en negativ effekt på -6.96, mens model_year har en positiv effekt på 3.04. Cylinders har en negativ effekt på -0.26, som kan indikere at mye av informasjonen allerede er blitt fanget opp av de andre trekkene.\n",
    "\n",
    "For å konkludere: Å legge til flere trekk vil ikke nødvendigvis forbedre modellen vår. Selv om cylinders og displacement virker svært relevant og åpenbare å ta med, så gir de faktisk i dette tilfellet lite ny relevant informasjon. Resultatet viser jo at det å legge dem til kan gjøre generaliseringen mindre optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51cc9c",
   "metadata": {},
   "source": [
    "**Oppgave 1.4.3** (*Bonus*): Prøv forskjellige kombinasjoner av trekk i datasettet og rapporter den laveste MSE-en du finner på valideringsdataene. Du kan bruke hvilken som helst tilnærming for å prøve ut trekk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b20c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection (validation mse)\n",
      "--------------------------------------------------\n",
      "Best comb: ('acceleration', 'model_year', 'cylinders', 'displacement')\n",
      "Best validation mse: 9.2647\n",
      "\n",
      "Top 10 combinations:\n",
      " 1. mse=9.2647 features=('acceleration', 'model_year', 'cylinders', 'displacement')\n",
      " 2. mse=9.2891 features=('acceleration', 'model_year', 'displacement')\n",
      " 3. mse=9.4894 features=('model_year', 'cylinders', 'displacement')\n",
      " 4. mse=9.5349 features=('model_year', 'displacement')\n",
      " 5. mse=9.9806 features=('acceleration', 'horsepower', 'model_year', 'cylinders', 'displacement')\n",
      " 6. mse=10.0730 features=('acceleration', 'horsepower', 'model_year', 'displacement')\n",
      " 7. mse=10.2089 features=('horsepower', 'model_year', 'cylinders', 'displacement')\n",
      " 8. mse=10.3007 features=('horsepower', 'model_year', 'displacement')\n",
      " 9. mse=10.3262 features=('weight', 'model_year')\n",
      "10. mse=10.3306 features=('weight', 'horsepower', 'model_year')\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Lager dette til en funksjon for enkelthets skyld\n",
    "def evaluate_feature_set(feat_name):\n",
    "    \"\"\"\n",
    "    Trener LinearRegression på train-splitt og evaluerer mse på val-splitt for en gitt liste med feature-navn.\n",
    "    \"\"\"\n",
    "    mpg_data = get_auto_mpg_data(\n",
    "        columns_to_include=list(feat_name),\n",
    "        perform_scaling=True,\n",
    "    )\n",
    "\n",
    "    x_train = mpg_data[\"x_train\"]\n",
    "    y_train = mpg_data[\"y_train\"]\n",
    "    x_val = mpg_data[\"x_val\"]\n",
    "    y_val = mpg_data[\"y_val\"]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_val_predicated = model.predict(x_val)\n",
    "    mse_val = calculate_mse(y_val, y_val_predicated)\n",
    "\n",
    "    return mse_val\n",
    "\n",
    "def find_best_feat_comb():\n",
    "    \"\"\"\n",
    "    Bonus oppgave 1.4.3:\n",
    "    prøv ulike kombinasjoner av features og finn den som gir lavest mse på val-splitten.\n",
    "\n",
    "    Vi bruker val-splitt fordi:\n",
    "    - Train brukes til å lære, fit().\n",
    "    - Val brukes til å velge modell (feature-set).\n",
    "    - Hvis vi hadde valgt basert på val, blir val-feilen et optimistisk (biased) estimat, siden vi optimaliserer mot den.\n",
    "    \"\"\"\n",
    "\n",
    "    # Her er feature trekkene\n",
    "    all_features = [\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "        \"horsepower\",\n",
    "        \"model_year\",\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "    ]\n",
    "\n",
    "    best_mse = float(\"inf\")\n",
    "    best_feature = None\n",
    "\n",
    "    # For å lagre og printe det senere\n",
    "    results = []\n",
    "\n",
    "    # Prøver alle kombinasjoner\n",
    "    for i in range(1, len(all_features) + 1):\n",
    "        for feat_comb in combinations(all_features, i):\n",
    "            mse_val = evaluate_feature_set(feat_comb)\n",
    "\n",
    "            results.append((mse_val, feat_comb))\n",
    "\n",
    "            # Sjekker om dette er beste kombinasjonen hittil\n",
    "            if mse_val < best_mse:\n",
    "                best_mse = mse_val\n",
    "                best_feature = feat_comb\n",
    "\n",
    "    # Sorterer resultatene, fra lavest mse\n",
    "    results.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Pen printout\n",
    "    print(\"Feature selection (validation mse)\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Best comb: {best_feature}\")\n",
    "    print(f\"Best validation mse: {best_mse:.4f}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Top 10 combinations:\")\n",
    "    for i, (mse, comb) in enumerate(results[:10], start=1):\n",
    "        print(f\"{i:2d}. mse={mse:.4f} features={comb}\")\n",
    "\n",
    "    return best_feature, best_mse\n",
    "\n",
    "# Kjøring av 1.4.3:\n",
    "best_features, best_val_mse = find_best_feat_comb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645acf7",
   "metadata": {},
   "source": [
    "### Resonnement for oppgave 1.4.3:\n",
    "Validation mse: 9.2647 er den laveste validerinsfeilen blant alle de testede kombinasjonene.\n",
    "\n",
    "Overraskende nok, så er ikke weight og horsepower med i den beste modellen, dette er overraskende på grunn av at det tidligere har vært en sterk predikator. Mye sannsynlig kunne dette bli den beste modellen på grunn av at informasjonen weight gir også blir gitt av de andre feature-ene. \n",
    "Et mulig eksempel er at tyngre biler ofte har større motorvolum og flere sylindere, så disse trekkene kan være sterkt korrelerte, altså et eksempel på multikollinearitet, der flere trekk altså beskriver de samme egenskapene.\n",
    "\n",
    "Vi ser at feature model_year forekommer i nesten alle kombinasjonene, som tyder på at bilens produksjonsår har mye å si for drivstoffeffektiviteten.\n",
    "\n",
    "Displacement (motorvolumet til bilen) inngår i mange av kombinasjoenene som sannsynligvis kommer av at større motorvolum ofte innebærer høyere forbruk.\n",
    "\n",
    "Vi kan igjen se på at mse-verdien vi fikk på 9.2647 nå er enda bedre enn 10.6 vi fikk for 4 features og betydelig bedre enn det første vi testet, nemlig for 2 trekk som ga oss rundt 18 i mse-verdi.\n",
    "Vi kan konkludere med at en mer optimal trekk-seleksjon reduserer prediksjonsfeilen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ead34",
   "metadata": {},
   "source": [
    "**Oppgave 1.4.4:** (*Bonus*) Bruk den beste modellen (modellen trent på trekkene som gir lavest valideringstap) til å lage prediksjoner for testdataene og rapporter tapet. Dere kan hente testdataene med `mpg_data[\"x_test\"]` og `mpg_data[\"y_test\"]`.\n",
    "\n",
    "Grunnen til at vi gjør dette er å få et mer realistisk anslag på hvordan den endelige modellen vil prestere på usette datapunkter. Når vi trener mange modeller og velger den med lavest valideringsfeil, blir denne feilen et dårlig estimat for den faktiske generaliseringsfeilen, nettopp fordi modellen er valgt på grunn av sin lave valideringsfeil. Derfor holder vi av et eget testdatasett som ikke brukes i verken prosessering eller trening, slik at dataene er helt nye både for modellen og for dem som utvikler den. På den måten unngår vi modeller som presterer godt på trenings- og valideringsdata, men dårligere ellers - noe som ofte kan skje med kraftigere modeller som dype nevrale nettverk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66cce0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The final evaluation on the TEST set\n",
      "--------------------------------------------------\n",
      "Chosen features: ('acceleration', 'model_year', 'cylinders', 'displacement')\n",
      "Test mse: 14.8718\n"
     ]
    }
   ],
   "source": [
    "def evaluate_best_on_test(best_features):\n",
    "    \"\"\"\n",
    "    Bonus oppgave 1.4.4:\n",
    "    Denne funksjonen er for å bruke den beste feature-kombinasjonen og evaluere det på test-splitten.\n",
    "\n",
    "    Notat:\n",
    "    - Vi bruker opp val-splitten til modellvalget.\n",
    "    - test-splittet skal ikke brukes før modellen er ferdig.\n",
    "    - Test-feilen vil være et bedre estimat på generaliseringsfeil i dette tilfellet, kontro val-feilene.\n",
    "    \"\"\"\n",
    "\n",
    "    mpg_data = get_auto_mpg_data(\n",
    "        columns_to_include=list(best_features),\n",
    "        perform_scaling=True,\n",
    "    )\n",
    "\n",
    "    x_train = mpg_data[\"x_train\"]\n",
    "    y_train = mpg_data[\"y_train\"]\n",
    "    x_test = mpg_data[\"x_test\"]\n",
    "    y_test = mpg_data[\"y_test\"]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_test_predicat = model.predict(x_test)\n",
    "    mse_test = calculate_mse(y_test, y_test_predicat)\n",
    "\n",
    "    # printout\n",
    "    print(\"\\nThe final evaluation on the TEST set\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Chosen features: {best_features}\")\n",
    "    print(f\"Test mse: {mse_test:.4f}\")\n",
    "\n",
    "    return mse_test\n",
    "\n",
    "# Kjøring av 1.4.4\n",
    "mse_test = evaluate_best_on_test(best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1967f",
   "metadata": {},
   "source": [
    "### Resonnement for oppgave 1.4.4:\n",
    "Som vi kan se er trekkene: acceleration, model_year, cylinders og discplacement. Vi fikk en validation mse på 9.2647 i sted og vi får nå en test mse-verdi på 14.8718.\n",
    "\n",
    "Test-mse verdien er høyere enn validerings mse-verdien vi fikk. Modellen presterer altså dårligere på de helt nye dataene enn på valideringsdataene.\n",
    "\n",
    "En grunn til at dette skjer kan ha å gjøre med at valideringssettet ble brukt til å velge den beste kombinasjonen. Det er en risiko for at når man tester mange validerings kombinasjoner og at man velger den med hittil lavest verdi at vi har tilpasset oss valideringsdataene for nærme/godt til akkurat dem. Vi kan derfor få et optimistisk estimat.\n",
    "\n",
    "Siden testsettet er helt nytt og ikke blitt brukt til å lage modellen eller treningen, så kan vi faktisk anta at det gir oss et mye mer realistisk estimat med tanke på hvordan modellen ville prestert på helt nye datapunkter den blir satt til å jobbe med i fremtiden.\n",
    "\n",
    "Samtidig så kan det faktisk være at modellen ikke var overtilpasset valideringssettet, men at valideringssettet rett og slett var enklere å predikere sammenlignet med testsettet. \n",
    "Den siste muligheten er at det da er en blanding av begge grunnene.\n",
    "\n",
    "For å konkludere, så forbedret feature selection modellen på valideringsdataene våre, mens testresultatet viser at generaliseringsevnen ikke er like god som valideringsfeilen indikerte. \n",
    "Det er altså veldig viktig å ikke bruke test datasettet til treningen eller modellbyggingen og heller bruke det når alt er ferdig for å finne en mer realistisk evaluering av modellens egenskaper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26fa4d",
   "metadata": {},
   "source": [
    "## Del 2 - Logistisk regresjon [Totalt 13p og 3b]\n",
    "\n",
    "### 2.0 - Bakgrunn og datasett [2p, 1b]\n",
    "\n",
    "I denne delen tar vi for oss binær klassifikasjon med *logistisk regresjon*. Mens lineær regresjon brukes for regresjonsoppgaver der målet er å forutsi reelle tall, brukes logistisk regresjon for klassifikasjonsoppgaver der målet er å tilordne eksempler til _ulike klasser_. Binær klassifikasjon handler om å klassifisere mellom to klasser, for eksempel \"ja\" eller \"nei\", eller \"0\" eller \"1\".\n",
    "\n",
    "I binær klassifikasjon er de sanne verdiene $y_i$ enten lik 0 eller lik 1 (dette kan representere binære merkelapper som for eksempel \"ikke-hund\" og \"hund\"). Prediksjonene $\\hat{y}_i$ er reelle tall mellom 0 og 1.\n",
    "\n",
    "Selv om logistisk regresjon er en annen modell enn lineær regresjon, er det mange likheter. Det er derfor mulig å gjenbruke noe av koden og metodologien brukt i den første delen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e1e3d",
   "metadata": {},
   "source": [
    "Datasettet vi skal bruke heter [*Spambase*](https://archive.ics.uci.edu/dataset/94/spambasefor), som er et datasett med trekk (features) fra 4601 e-poster som er markert som spam eller ikke-spam (de sanne verdiene). E-postene har totalt 57 trekk, der vi skal starte med en mindre delmengde av dem. Trekkene beskriver frekvensen av spesifikke ord, tegn og store bokstaver. Vi starter med følgende trekk:\n",
    "\n",
    "- `word_freq_free`: Frekvensen av ordet `free` i e-posten.\n",
    "- `char_freq_%24`: Frekvensen av tegnet `$` i e-posten (enkodingen `%24` representerer tegnet `$`).\n",
    "- `capital_run_length_total`: Summen av antall store bokstaver i e-posten.\n",
    "\n",
    "I datasettet er \"frekvensen\" av et ord målt ved antall `100` * `forekomster av ordet` / `totalt antall ord i e-posten` og tilsvarende for frekvensen av tegn.\n",
    "\n",
    "Datasettet kan lastes med følgende:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7198f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = get_spambase_data(\n",
    "    columns_to_include=[\"word_freq_free\", \"char_freq_%24\", \"capital_run_length_total\"],\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    perform_scaling=False,\n",
    ")\n",
    "# x_train -> har shape [n, p] der (n e-poster, p features)\n",
    "x_train = spam_data[\"x_train\"]\n",
    "# y_train -> har shape [n] der (0 = ikke spam, 1 = spam)\n",
    "y_train = spam_data[\"y_train\"]\n",
    "x_val = spam_data[\"x_val\"]\n",
    "y_val = spam_data[\"y_val\"]\n",
    "\n",
    "# Henter navnene fra trekkene\n",
    "feature_names = spam_data[\"feature_names\"]\n",
    "print(\"Feature names:\", feature_names)\n",
    "\n",
    "# Henter kolonnen for store bokstaver\n",
    "capital_letters = x_train[:, 2]\n",
    "\n",
    "# Finner maksimumsverdien\n",
    "max_capital_letters = capital_letters.max()\n",
    "\n",
    "print(f\"a) Høyeste antall store bokstaver i en e-post: {max_capital_letters}\")\n",
    "\n",
    "# Antall spam (1), lager en boolsk array der True for spam, der np.sum(True) = 1, vektorisert uten løkke.\n",
    "num_spam = np.sum(y_train == 1)\n",
    "\n",
    "# Antall ikke-spam (0)\n",
    "num_not_spam = np.sum(y_train == 0)\n",
    "\n",
    "print(f\"b) Antall spam: {num_spam}\")\n",
    "print(f\"   Antall ikke-spam: {num_not_spam}\")\n",
    "\n",
    "# Henter kolonnen for $-frekvensen\n",
    "dollar_freq = x_train[:, 1]\n",
    "\n",
    "# Finner maksimum\n",
    "max_dollar_freq = dollar_freq.max()\n",
    "\n",
    "print(f\"c) Høyeste frekvens av $: {max_dollar_freq}\")\n",
    "\n",
    "# x_train[mask, kolonne] -> Først filtreres radene så hentes kolonnene.\n",
    "\n",
    "# Lager en maske for ikke-spam\n",
    "not_spam_mask = (y_train == 0)\n",
    "\n",
    "# Bruker masken til å hente kun ikke-spam rader\n",
    "dollar_freq_not_spam = x_train[not_spam_mask, 1]\n",
    "\n",
    "# Finner maksimum blant disse\n",
    "max_dollar_not_spam = dollar_freq_not_spam.max()\n",
    "\n",
    "print(f\"d) Høyeste frekvens av $ i ikke-spam: {max_dollar_not_spam}\")\n",
    "\n",
    "# Maske for spam\n",
    "spam_mask = (y_train == 1)\n",
    "\n",
    "# Maske for ikke-spam\n",
    "not_spam_mask = (y_train == 0)\n",
    "\n",
    "# Henter kapitalbokstav-kolonnen\n",
    "capital_letters = x_train[:, 2]\n",
    "\n",
    "# Gjennomsnitt for spam\n",
    "mean_capital_spam = capital_letters[spam_mask].mean()\n",
    "\n",
    "# Gjennomsnitt for ikke-spam\n",
    "mean_capital_not_spam = capital_letters[not_spam_mask].mean()\n",
    "\n",
    "print(\"e) Gjennomsnittlig antall store bokstaver:\")\n",
    "print(f\"  Spam: {mean_capital_spam}\")\n",
    "print(f\"  Spam: {mean_capital_not_spam}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534fee2",
   "metadata": {},
   "source": [
    "**Oppgave 2.0**: Vi begynner med å undersøke datasettet. I alle deloppgavene under skal vi kun jobbe med dataene i treningssplitten. Navnet på trekkene kan hentes med `spam_data[\"feature_names\"]`, og y-dataene angir spam-e-poster som `1` og ikke-spam som `0`.\n",
    "\n",
    "- a) Hva er det høyeste antallet store bokstaver i en e-post?\n",
    "- b) Hvor er antallet spam og ikke-spam e-poster?\n",
    "- c) Hva er det høyeste frekvensen av tegnet `$` i en e-post?\n",
    "- d) Hva er det høyeste frekvensen av tegnet `$` i en e-post som *ikke* er spam?\n",
    "- e) [Bonus] Hva er gjennomsnittlig antall store bokstaver i spam e-poster, og gjennomsnittlig antall store bokstaver i ikke-spam e-poster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999bb40",
   "metadata": {},
   "source": [
    "### 2.1 - Binær kryssentropi [3p]\n",
    "\n",
    "I regresjon brukte vi tapsfunksjonen MSE, mens vi kommer til å bruke *binær kryssentropi* for logistisk regresjon, som oftest kalt *binary cross entropy* (BCE). Navnet \"kryssentropi\" kommer fra informasjonsteori, en annen gren innenfor informatikk, men funksjonen passer godt som tapsfunksjon for klassifikasjon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ee3c1",
   "metadata": {},
   "source": [
    "La oss først se på hvordan og hvorfor BCE fungerer. Vi starter med definisjonen av BCE for et enkelt datapunkt $i$, som er:\n",
    "$$\n",
    "\\begin{align*}\n",
    "l_{\\text{BCE}}(y_i, \\hat{y}_i) & = \n",
    "\\begin{cases}\n",
    "- \\log(1 - \\hat{y}_i), & \\text{hvis } y_i = 0, \\\\\n",
    "- \\log(\\hat{y}_i), & \\text{hvis } y_i = 1.\n",
    "\\end{cases} \\\\[8mm]\n",
    "\\text{\\textrm{noe som kan også skrives:}} & \\\\[4mm]\n",
    "&=  - \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i)\\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d191b6",
   "metadata": {},
   "source": [
    "Det gjennomsnittlige tapet for et helt datasett og en BCE-tapsfunksjon er dermed:\n",
    "\n",
    "$$\\begin{align*} \\hat{L}_{\\text{BCE}}(\\textbf{y}, \\hat{\\textbf{y}}) & = \\frac{1}{n} \\sum_{i=1}^{n} l_{\\text{BCE}}(y_i, \\hat{y}_i) \\\\\n",
    "& = - \\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i)\\right] \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004d8cd",
   "metadata": {},
   "source": [
    "La oss kort se på `log()`-delen, altså logaritmen. Generelt sett er logaritmer definert som den inverse funksjonen av potenser, men vi trenger kun å se på tilfellet der inputet er mellom 0 og 1. Da er det to ting å legge merke til: $\\log(1) = 0$, og $\\log(x)$ nærmerer seg minus uendelig når $x$ nærmer seg 0. Dette minuset er opphavet til minuset i starten av formelen for BCE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93310a1",
   "metadata": {},
   "source": [
    "**Oppgave 2.1.1**: Her er noen veiledende spørsmål for å bli kjent med BCE.\n",
    "\n",
    "- a) For et gitt datapunkt, anta at $y = 0$. Hva blir BCE dersom modellen predikerer nøyaktig 0?\n",
    "- b) Hva omtrent blir BCE dersom modellen predikerer et tall veldig nærme 1?\n",
    "- c) Anta så at $y = 1$. Hva blir BCE dersom modellen predikerer nøyaktig 1?\n",
    "- d) Hva blir BCE om modellen predikerer et tall veldig nærme 0?\n",
    "- e) Prøv å beskrive i én setning hvorfor de fire egenskapene over er gunstig for en tapsfunksjon.\n",
    "\n",
    "**Hint**: Ukesoppgavene i uke 6 går igjennom BCE i nærmere detalj."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277069b9",
   "metadata": {},
   "source": [
    "**Oppgave 2.1.2**: Implementer funksjonen `calculate_bce()`, som gitt to arrayer av samme lengde regner ut binær kryssentropi (BCE) av de to arrayene. Bruk `np.log()` for logaritmen. Som med MSE kan dere velge om dere vil vektorisere koden eller ikke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5096ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: `test_calculate_bce`. Not implemented (returned `None`). \n"
     ]
    }
   ],
   "source": [
    "def calculate_bce(y_data, predictions):\n",
    "    \"\"\"\n",
    "    Returns the binary cross entropy (BCE) of the input values.\n",
    "\n",
    "    Args:\n",
    "        y_data (np.array): [n]-shaped array of true values (zeros or ones).\n",
    "        predictions (np.array): [n]-shaped array of predictions (between zero and one).\n",
    "\n",
    "    Returns:\n",
    "        float: The BCE.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "test_calculate_bce(input_function=calculate_bce, message_on_pass=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc703ebb",
   "metadata": {},
   "source": [
    "### 2.2 - Prediksjon [2p]\n",
    "\n",
    "Prediksjon er noe forskjellig for lineær regresjon og logistisk regresjon. For lineær regresjon ganget vi vektene med de tilsvarende trekkene og plusset på konstantleddet, som kan gi et tall mellom minus og pluss uendelig. For logistisk regresjon gjør vi først det samme steget, men så putter vi dette tallet inn i en *sigmoid* funksjon som gir et tall mellom 0 og 1.\n",
    "\n",
    "Sigmoid-funksjonen, som ofte er representert ved $\\sigma$ (det greske symbolet uttalt \"sigma\"), er definert ved:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5b711",
   "metadata": {},
   "source": [
    "Her er $e$ den matematiske konstanten [*Eulers konstant*](https://en.wikipedia.org/wiki/E_(mathematical_constant)), men i praksis spiller det liten rolle hvilket tall som blir brukt, så det er ikke nødvendig å ha noe særlig forståelse for dette tallet. En ting som kan hjelpe med forståelsen er at $e^{-x}$ går mot $0$ når $x$ er veldig høyt og går mot uendelig når $x$ har en høy negativ verdi. Det medfører at *$\\sigma(x)$ blir nærme 0 når x har en høy negativ verdi og nærme 1 når $x$ har en høy positiv verdi*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da3bc8",
   "metadata": {},
   "source": [
    "**Oppgave 2.2.1**: Implementer funksjonen `sigmoid()` som regner ut sigmoid-funksjonen. Bruk `np.exp()` for potensen, der `np.exp(x)` $ = e^x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "414e25d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: `test_sigmoid`. Not implemented (returned `None`). \n"
     ]
    }
   ],
   "source": [
    "def sigmoid(values):\n",
    "    \"\"\"\n",
    "    Calculates the sigmoid function of the input, sigmoid(x) = 1 / (1 + e^(-x))\n",
    "\n",
    "    Args:\n",
    "        values (np.array): [n]-shaped array of values to send to the sigmoid function.\n",
    "\n",
    "    Returns:\n",
    "        np.array: [n]-shaped array of float values corresponding to the output of the sigmoid function.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "test_sigmoid(input_function=sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884b645",
   "metadata": {},
   "source": [
    "Prediksjon for logistisk regresjon blir altså å først regne ut vektene ganger trekkene pluss konstantleddet, slik som med lineær regresjon, og så putte dette inn i sigmoid-funksjonen. Vektene ganger trekkene pluss konstantleddet blir ofte notert med $z$, kalt *den vektede summen* (eng: *weighted sum*), og vi kan skrive formelen for prediksjon som:\n",
    "\n",
    "$$\\hat{y} = \\sigma(z) = \\sigma\\left(\\sum_{i=1}^n \\beta_i \\cdot x_i + \\beta_0\\right)$$\n",
    "\n",
    "Vi kan visualisere logistisk regresjon i følgende diagram:\n",
    "\n",
    "<!-- markdownlint-disable-next-line MD033 -->\n",
    "<img src=\"bilder/logistic_regression_general_formula.png\" alt=\"Linear regression diagram\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3064ec",
   "metadata": {},
   "source": [
    "**Oppgave 2.2.2** Implementer funksjonen `logistic_regression_predict()`. Som med lineær regresjon skal metoden ta inn en to-dimensjonal array av dimensjon $[n, p]$, der hver rad er et datapunkt og kolonnene tilsvarer trekk i inputen, og returnere en vektor av lengde $[n]$ med prediksjoner basert på formelen over. Bruk `sigmoid` implementasjonen deres fra oppgave 2.2.1.  \n",
    "**Tips**: Det er mulig å gjenbruke mye av koden fra lineær regresjon, det er kun nødvendig å legge til sigmoid-funksjonen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9dc7268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: `test_predict_logistic_regression`. Not implemented (`predict()` returned `None`). \n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_predict(x_data, coefficients):\n",
    "    \"\"\"\n",
    "    Given input data `x_data` of shape [n, p] (`n` datapoints and `p` features)\n",
    "    and `coefficients` of shape [p + 1], returns the predictions the model\n",
    "    gives as an [n]-length array.\n",
    "\n",
    "    Args:\n",
    "        x_data (np.array): [n, p]-shaped array of input data.\n",
    "        coefficient (np.array): [p + 1]-shaped array of coefficient. Element number\n",
    "            zero corresponds to the bias while element one to p corresponds to\n",
    "            the weight for feature 1 to p.\n",
    "\n",
    "    Returns:\n",
    "        np.array: [n]-shaped data of corresponding predictions.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "test_predict_logistic_regression(input_function=logistic_regression_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635100b",
   "metadata": {},
   "source": [
    "### 2.3 - Kjøring og evaluering av logistisk regresjon [3p]\n",
    "\n",
    "Det er på tide å kjøre modellen vår på datasettet og klassifisere e-poster som spam eller ikke-spam.\n",
    "\n",
    "**Oppgave 2.3.1**: Tren modellen på treningsdatasettet, prediker på evalueringsdataene og rapporter BCE-en. Dere kan bruke `model = LogisticRegression()` og `model.fit()` som med lineær regresjon. For å få sigmoid-verdiene (prediksjonene før de er rundet av til 0 eller 1) kan dere bruke `model.predict_proba(X=x_val)[:, 1]`, siden `model.predict()` vil returnere klassifikasjonene, altså verdiene etter de er rundet av til 0 eller 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b617aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = get_spambase_data(\n",
    "    columns_to_include=[\"word_freq_free\", \"char_freq_%24\", \"capital_run_length_total\"],\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    perform_scaling=True,\n",
    ")\n",
    "x_train = spam_data[\"x_train\"]\n",
    "y_train = spam_data[\"y_train\"]\n",
    "x_val = spam_data[\"x_val\"]\n",
    "y_val = spam_data[\"y_val\"]\n",
    "\n",
    "model = LogisticRegression()\n",
    "# TODO: Train (fit) model on training set, predict probabilities on the evaluation set and report the BCE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3b430",
   "metadata": {},
   "source": [
    "Det neste steget er å evaluere modellen med *nøyaktighet* (accuracy). Nøyaktighet regner ut forholdet mellom korrekt klassifiserte datapunkter og totalt antall datapunkter. Med sanne verdier $\\textbf{y} = (y_1, y_2, ..., y_n)$ og klassifikasjoner $\\textbf{k} = (k_1, k_2, ..., k_n)$ (der hver $y_i$ og $k_i$ er enten 0 eller 1), kan vi beregne nøyaktighet som:\n",
    "\n",
    "$$\\text{accuracy}(\\textbf{y}, \\textbf{k}) = \\frac{1}{n} \\sum_{i=1}^n I(y_i = k_i)$$\n",
    "\n",
    "der $I$ er identitetsfunksjonen, som returnerer 1 dersom argumentet er sant, og 0 ellers.\n",
    "\n",
    "Prediksjonene fra `model.predict_proba()` returnerer verdiene fra sigmoid-funksjonen, men for å regne ut nøyaktighet må verdiene være nøyaktig lik 0 eller 1. Det kan man enkelt få ved å runde av verdier til 0 eller 1 med en terskelverdi, for eksempel 0.5. Dette gjør metoden `model.predict()`.\n",
    "\n",
    "**Oppgave 2.3.2** Implementer funksjonen `calculate_accuracy()` som tar inn to binære arrayer av samme lengde og returnerer nøyaktigheten. Rapporter deretter nøyaktigheten til modellen fra oppgave 2.2.1 på valideringsdataene. Hadde du vært fornøyd med en algoritme for å klassifisere spam med denne nøyaktigheten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d769894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: `test_calculate_accuracy`. Not implemented (returned `None`). \n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(y_data, classifications):\n",
    "    \"\"\"\n",
    "    Calculates accuracy on provided input.\n",
    "\n",
    "    Args:\n",
    "        y_data (np.array): [n]-shaped array of true values.\n",
    "        classifications (_type_): [n]-shaped array of classifications.\n",
    "\n",
    "    Returns:a\n",
    "        int: The accuracy for the inputs.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "test_calculate_accuracy(input_function=calculate_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bd74e",
   "metadata": {},
   "source": [
    "### 2.4 - Fullt datasett og tolkning [3p, 2b]\n",
    "\n",
    "Hittil har vi bare brukt 3 av de 57 trekkene i datasettet. Med den generelle implementasjonen av klassen vår kan vi derimot bruke et vilkårlig antall trekk. La oss prøve å trene modellen med alle trekkene.\n",
    "\n",
    "**Oppgave 2.4.1**: Tren den logistiske modellen med alle trekkene i datasettet og rapporter nøyaktigheten. Hadde dette vært tilstrekkelig for å bruke modellen til å klassifisere spam i praksis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3bb281d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = get_spambase_data(\n",
    "    columns_to_include=None,  # Corresponds to all features\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    perform_scaling=True,\n",
    ")\n",
    "x_train = spam_data[\"x_train\"]\n",
    "y_train = spam_data[\"y_train\"]\n",
    "x_val = spam_data[\"x_val\"]\n",
    "y_val = spam_data[\"y_val\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da31bf",
   "metadata": {},
   "source": [
    "**Oppgave 2.4.2**: La oss til slutt reflektere litt over resultatet til modellen.\n",
    "\n",
    "a) Anta at modellen for spam-klassifisering ble implementert i et ekte e-postfilter. Det er to måter å filtrere e-poster feil på: den ene er å klassifisere spam som ikke-spam, den andre er å klassifisere ikke-spam som spam. Synes du de to typene feil er like dårlige for filteret i praksis, eller vil en type feil være mer problematisk enn den andre? Forklar kort hvorfor du synes det.\n",
    "\n",
    "b) Hvordan kunne du ha endret modellen slik at man kan prioritere å unngå den ene typen feil over den andre?\n",
    "\n",
    "c) (*Bonus*) Datasettet vårt består av 57 trekk som allerede er manuelt bearbeidet gjennom såkalt _feature engineering_. Har du forslag til andre trekk som kunne vært inkludert for å bedre predikere om e-poster er spam eller ikke?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f16da",
   "metadata": {},
   "source": [
    "**Oppgave 2.4.3** (*Bonus*): Tren modellen på forskjellige kombinasjoner av trekk og finn kombinasjonen som gir lavest tap på valideringsdataene. Rapporter nøyaktigheten på testdataene til den kombinasjonen som ga lavest valideringstap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e88576",
   "metadata": {},
   "source": [
    "## Oppsummering\n",
    "\n",
    "I denne obligen har vi sett på lineær og logistisk regresjon, der vi har implementert funksjonalitet som tapsfunksjoner og prediksjon, trent modeller med `sklearn` og tolket resultatet. Selv om både lineær og logistisk regresjon er enkle modeller, er de fortsatt svært effektive og mye brukte. Med god forbehandling av data og trekk kan lineær og logistisk regresjon gi mer enn tilstrekkelig ytelse, og til og med overgå mer komplekse modeller, spesielt med små datasett. De kan også bli brukt for å evaluere andre metoder ved å bruke resultatet som en *baseline* som kan sammenliknes med andre modellers resultat.\n",
    "\n",
    "I faget IN2160 implementeres lineær og logistisk regresjon helt fra bunnen av, inkludert optimalisering av koeffisientene med gradientnedstigning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
